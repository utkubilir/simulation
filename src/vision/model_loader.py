"""
Harici Model ve Veri YÃ¼kleme YÃ¶neticisi

YOLO modellerini ve dataset'leri projeye aktarmak iÃ§in kullanÄ±lÄ±r.
"""

from pathlib import Path
import shutil
import json
from typing import List, Dict, Optional
from datetime import datetime


class ModelLoader:
    """
    Harici YOLO modelleri ve dataset'leri yÃ¶netir
    
    KullanÄ±m:
        loader = ModelLoader()
        
        # Kendi modelinizi import edin
        loader.import_model('/path/to/your/best.pt', 'my_uav_model')
        
        # Dataset import edin
        loader.import_dataset('/path/to/dataset/', 'uav_dataset_v1')
        
        # Mevcut modelleri listele
        models = loader.list_models()
        
        # Model yolunu al
        path = loader.get_model_path('my_uav_model')
    """
    
    # VarsayÄ±lan dizinler
    MODELS_DIR = Path('models/custom')
    DATASETS_DIR = Path('data/custom')
    PRETRAINED_DIR = Path('models/pretrained')
    
    def __init__(self, base_path: str = None):
        """
        Args:
            base_path: Proje kÃ¶k dizini (None ise mevcut dizin)
        """
        if base_path:
            base = Path(base_path)
            self.MODELS_DIR = base / 'models' / 'custom'
            self.DATASETS_DIR = base / 'data' / 'custom'
            self.PRETRAINED_DIR = base / 'models' / 'pretrained'
            
        # Dizinleri oluÅŸtur
        self.MODELS_DIR.mkdir(parents=True, exist_ok=True)
        self.DATASETS_DIR.mkdir(parents=True, exist_ok=True)
        self.PRETRAINED_DIR.mkdir(parents=True, exist_ok=True)
        
        # Model metadata dosyasÄ±
        self.metadata_file = self.MODELS_DIR / 'metadata.json'
        self.metadata = self._load_metadata()
        
    def _load_metadata(self) -> Dict:
        """Metadata dosyasÄ±nÄ± yÃ¼kle"""
        if self.metadata_file.exists():
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {'models': {}, 'datasets': {}}
        
    def _save_metadata(self):
        """Metadata dosyasÄ±nÄ± kaydet"""
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, indent=2, ensure_ascii=False)
            
    def import_model(self, source_path: str, model_name: str, 
                     description: str = None, classes: List[str] = None) -> Path:
        """
        Harici YOLO modelini projeye aktar
        
        Args:
            source_path: Kaynak .pt dosyasÄ±
            model_name: Model iÃ§in isim (boÅŸluksuz)
            description: Model aÃ§Ä±klamasÄ±
            classes: Model sÄ±nÄ±flarÄ± listesi
            
        Returns:
            Kopyalanan model dosyasÄ±nÄ±n yolu
        """
        source = Path(source_path)
        
        if not source.exists():
            raise FileNotFoundError(f"Model dosyasÄ± bulunamadÄ±: {source}")
            
        if not source.suffix == '.pt':
            raise ValueError("Model dosyasÄ± .pt uzantÄ±lÄ± olmalÄ±dÄ±r")
            
        # GeÃ§ersiz karakterleri temizle
        safe_name = "".join(c for c in model_name if c.isalnum() or c in ('_', '-'))
        
        # Hedef yol
        dest = self.MODELS_DIR / f"{safe_name}.pt"
        
        # Kopyala
        shutil.copy(source, dest)
        
        # Metadata gÃ¼ncelle
        self.metadata['models'][safe_name] = {
            'path': str(dest),
            'original_path': str(source),
            'description': description or '',
            'classes': classes or ['uav'],
            'imported_at': datetime.now().isoformat(),
            'size_mb': dest.stat().st_size / (1024 * 1024)
        }
        self._save_metadata()
        
        print(f"âœ“ Model aktarÄ±ldÄ±: {dest}")
        print(f"  Boyut: {self.metadata['models'][safe_name]['size_mb']:.2f} MB")
        
        return dest
        
    def import_dataset(self, source_dir: str, dataset_name: str,
                       description: str = None) -> Path:
        """
        EÄŸitim/test dataset'ini projeye aktar
        
        Beklenen YOLO format yapÄ±sÄ±:
        source_dir/
        â”œâ”€â”€ images/
        â”‚   â”œâ”€â”€ train/
        â”‚   â”‚   â”œâ”€â”€ image1.jpg
        â”‚   â”‚   â””â”€â”€ ...
        â”‚   â””â”€â”€ val/
        â”‚       â”œâ”€â”€ image1.jpg
        â”‚       â””â”€â”€ ...
        â”œâ”€â”€ labels/
        â”‚   â”œâ”€â”€ train/
        â”‚   â”‚   â”œâ”€â”€ image1.txt
        â”‚   â”‚   â””â”€â”€ ...
        â”‚   â””â”€â”€ val/
        â”‚       â”œâ”€â”€ image1.txt
        â”‚       â””â”€â”€ ...
        â””â”€â”€ data.yaml (opsiyonel)
        
        Args:
            source_dir: Kaynak dataset dizini
            dataset_name: Dataset iÃ§in isim
            description: Dataset aÃ§Ä±klamasÄ±
            
        Returns:
            Kopyalanan dataset dizininin yolu
        """
        source = Path(source_dir)
        
        if not source.exists():
            raise FileNotFoundError(f"Dataset dizini bulunamadÄ±: {source}")
            
        if not source.is_dir():
            raise ValueError("source_dir bir dizin olmalÄ±dÄ±r")
            
        # YapÄ± kontrolÃ¼
        images_dir = source / 'images'
        labels_dir = source / 'labels'
        
        if not images_dir.exists():
            print(f"âš ï¸  UyarÄ±: 'images' dizini bulunamadÄ±")
        if not labels_dir.exists():
            print(f"âš ï¸  UyarÄ±: 'labels' dizini bulunamadÄ±")
            
        # GeÃ§ersiz karakterleri temizle
        safe_name = "".join(c for c in dataset_name if c.isalnum() or c in ('_', '-'))
        
        # Hedef yol
        dest = self.DATASETS_DIR / safe_name
        
        # Kopyala
        if dest.exists():
            shutil.rmtree(dest)
        shutil.copytree(source, dest)
        
        # Ä°statistikler
        train_images = len(list((dest / 'images' / 'train').glob('*'))) if (dest / 'images' / 'train').exists() else 0
        val_images = len(list((dest / 'images' / 'val').glob('*'))) if (dest / 'images' / 'val').exists() else 0
        
        # Metadata gÃ¼ncelle
        self.metadata['datasets'][safe_name] = {
            'path': str(dest),
            'original_path': str(source),
            'description': description or '',
            'imported_at': datetime.now().isoformat(),
            'train_images': train_images,
            'val_images': val_images
        }
        self._save_metadata()
        
        print(f"âœ“ Dataset aktarÄ±ldÄ±: {dest}")
        print(f"  EÄŸitim gÃ¶rÃ¼ntÃ¼leri: {train_images}")
        print(f"  DoÄŸrulama gÃ¶rÃ¼ntÃ¼leri: {val_images}")
        
        return dest
        
    def list_models(self) -> List[Dict]:
        """
        Mevcut modelleri listele
        
        Returns:
            Model bilgileri listesi
        """
        models = []
        
        for name, info in self.metadata.get('models', {}).items():
            path = Path(info['path'])
            if path.exists():
                models.append({
                    'name': name,
                    'path': str(path),
                    'description': info.get('description', ''),
                    'classes': info.get('classes', []),
                    'size_mb': info.get('size_mb', 0),
                    'imported_at': info.get('imported_at', '')
                })
                
        return models
        
    def list_datasets(self) -> List[Dict]:
        """
        Mevcut dataset'leri listele
        
        Returns:
            Dataset bilgileri listesi
        """
        datasets = []
        
        for name, info in self.metadata.get('datasets', {}).items():
            path = Path(info['path'])
            if path.exists():
                datasets.append({
                    'name': name,
                    'path': str(path),
                    'description': info.get('description', ''),
                    'train_images': info.get('train_images', 0),
                    'val_images': info.get('val_images', 0),
                    'imported_at': info.get('imported_at', '')
                })
                
        return datasets
        
    def get_model_path(self, model_name: str) -> Path:
        """
        Model dosya yolunu al
        
        Args:
            model_name: Model adÄ±
            
        Returns:
            Model dosyasÄ±nÄ±n yolu
        """
        if model_name in self.metadata.get('models', {}):
            path = Path(self.metadata['models'][model_name]['path'])
            if path.exists():
                return path
                
        # DoÄŸrudan dosya kontrolÃ¼
        direct_path = self.MODELS_DIR / f"{model_name}.pt"
        if direct_path.exists():
            return direct_path
            
        raise FileNotFoundError(f"Model bulunamadÄ±: {model_name}")
        
    def get_dataset_path(self, dataset_name: str) -> Path:
        """
        Dataset dizin yolunu al
        
        Args:
            dataset_name: Dataset adÄ±
            
        Returns:
            Dataset dizininin yolu
        """
        if dataset_name in self.metadata.get('datasets', {}):
            path = Path(self.metadata['datasets'][dataset_name]['path'])
            if path.exists():
                return path
                
        # DoÄŸrudan dizin kontrolÃ¼
        direct_path = self.DATASETS_DIR / dataset_name
        if direct_path.exists():
            return direct_path
            
        raise FileNotFoundError(f"Dataset bulunamadÄ±: {dataset_name}")
        
    def delete_model(self, model_name: str):
        """Model sil"""
        if model_name in self.metadata.get('models', {}):
            path = Path(self.metadata['models'][model_name]['path'])
            if path.exists():
                path.unlink()
            del self.metadata['models'][model_name]
            self._save_metadata()
            print(f"âœ“ Model silindi: {model_name}")
        else:
            print(f"âš ï¸  Model bulunamadÄ±: {model_name}")
            
    def delete_dataset(self, dataset_name: str):
        """Dataset sil"""
        if dataset_name in self.metadata.get('datasets', {}):
            path = Path(self.metadata['datasets'][dataset_name]['path'])
            if path.exists():
                shutil.rmtree(path)
            del self.metadata['datasets'][dataset_name]
            self._save_metadata()
            print(f"âœ“ Dataset silindi: {dataset_name}")
        else:
            print(f"âš ï¸  Dataset bulunamadÄ±: {dataset_name}")
            
    def create_dataset_yaml(self, dataset_name: str, classes: List[str] = None) -> Path:
        """
        YOLO format data.yaml dosyasÄ± oluÅŸtur
        
        Args:
            dataset_name: Dataset adÄ±
            classes: SÄ±nÄ±f isimleri listesi
            
        Returns:
            OluÅŸturulan yaml dosyasÄ±nÄ±n yolu
        """
        dataset_path = self.get_dataset_path(dataset_name)
        yaml_path = dataset_path / 'data.yaml'
        
        classes = classes or ['uav']
        
        content = f"""# YOLO Dataset Configuration
# Otomatik oluÅŸturuldu

path: {dataset_path.absolute()}
train: images/train
val: images/val

# SÄ±nÄ±flar
nc: {len(classes)}
names: {classes}
"""
        
        with open(yaml_path, 'w', encoding='utf-8') as f:
            f.write(content)
            
        print(f"âœ“ data.yaml oluÅŸturuldu: {yaml_path}")
        return yaml_path
        
    def print_summary(self):
        """Ã–zet bilgi yazdÄ±r"""
        models = self.list_models()
        datasets = self.list_datasets()
        
        print("\n" + "="*50)
        print("ğŸ“¦ Model ve Dataset Ã–zeti")
        print("="*50)
        
        print(f"\nğŸ¤– Modeller ({len(models)} adet):")
        if models:
            for m in models:
                print(f"   â€¢ {m['name']}: {m['size_mb']:.1f} MB")
        else:
            print("   (Model bulunamadÄ±)")
            
        print(f"\nğŸ“ Dataset'ler ({len(datasets)} adet):")
        if datasets:
            for d in datasets:
                total = d['train_images'] + d['val_images']
                print(f"   â€¢ {d['name']}: {total} gÃ¶rÃ¼ntÃ¼")
        else:
            print("   (Dataset bulunamadÄ±)")
            
        print("="*50 + "\n")
